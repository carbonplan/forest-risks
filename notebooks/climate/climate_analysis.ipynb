{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import zarr\n",
    "import os\n",
    "import bokeh\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from adlfs import AzureBlobFileSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import GatewayCluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = GatewayCluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.adapt(minimum=2, maximum=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load in your list of models for which downscaled climate simulations are\n",
    "available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = AzureBlobFileSystem(\n",
    "    \"carbonplan\", account_key=os.environ[\"BLOB_ACCOUNT_KEY\"]\n",
    ")\n",
    "file_list = fs.ls(\"carbonplan-scratch/downscaling/bias-correction\")\n",
    "files = [file.split(\"/\")[-2] for file in file_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load up a sample dataset to take a look at the domain and understand what\n",
    "you're working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_url = f\"downscaling/bias-correction/{files[40]}\"\n",
    "store = zarr.storage.ABSStore(\n",
    "    \"carbonplan-scratch\",\n",
    "    prefix=store_url,\n",
    "    account_name=\"carbonplan\",\n",
    "    account_key=os.environ[\"BLOB_ACCOUNT_KEY\"],\n",
    ")\n",
    "ds = xr.open_zarr(store, consolidated=True)\n",
    "ds.pr.isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can access the names of the individual GCMs that we have available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(set([(\".\").join(filename.split(\".\")[1:3]) for filename in files]))\n",
    "scenarios = [\n",
    "    (\"CMIP\", \"historical\", slice(\"1995-01-01\", \"2015-12-31\")),\n",
    "    (\"ScenarioMIP\", \"ssp245\", slice(\"2050-01-01\", \"2069-12-31\")),\n",
    "    (\"ScenarioMIP\", \"ssp370\", slice(\"2050-01-01\", \"2069-12-31\")),\n",
    "    (\"ScenarioMIP\", \"ssp585\", slice(\"2050-01-01\", \"2069-12-31\")),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's create a few bounding boxes to get at some regional differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_bounding_boxes = {\n",
    "    \"Pacific Northwest\": {\"lat\": [41, 49], \"lon\": [-130, -110]},\n",
    "    \"West\": {\"lat\": [20, 49], \"lon\": [-130, -105]},\n",
    "    \"Northeast\": {\"lat\": [41, 48], \"lon\": [-93, -66]},\n",
    "    \"Southeast\": {\"lat\": [25, 37], \"lon\": [-93, -76]},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then create a data array with dimensions [GCM, scenario, region] to house\n",
    "all of our analyses. We'll start with precipitation and then just copy it for\n",
    "tasmax and tasmin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation = xr.DataArray(\n",
    "    np.zeros((len(models), len(scenarios), len(region_bounding_boxes))),\n",
    "    dims=(\"gcm\", \"scenario\", \"region\"),\n",
    "    coords={\n",
    "        \"gcm\": models,\n",
    "        \"scenario\": [\"historical\", \"ssp245\", \"ssp370\", \"ssp585\"],\n",
    "        \"region\": list(region_bounding_boxes.keys()),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmax = precipitation.copy(deep=True)\n",
    "tasmin = precipitation.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fill each of the prepared summary arrays with the averages from all of\n",
    "the different GCMs for that multiple boxes for each scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_bounding_boxes.keys():\n",
    "    print(region)\n",
    "    lat_bounds = region_bounding_boxes[region][\"lat\"]\n",
    "    lon_bounds = region_bounding_boxes[region][\"lon\"]\n",
    "\n",
    "    for (experiment, scenario, time_slice) in scenarios:\n",
    "        for gcm in models:\n",
    "            store_url = f\"downscaling/bias-correction/{experiment}.{gcm}.{scenario}.Amon.gn\"\n",
    "            store = zarr.storage.ABSStore(\n",
    "                \"carbonplan-scratch\",\n",
    "                prefix=store_url,\n",
    "                account_name=\"carbonplan\",\n",
    "                account_key=os.environ[\"BLOB_ACCOUNT_KEY\"],\n",
    "            )\n",
    "            try:\n",
    "                ds = xr.open_zarr(store, consolidated=True)\n",
    "                print(store_url)\n",
    "                ds_box = (\n",
    "                    ds.where(ds.lat > lat_bounds[0])\n",
    "                    .where(ds.lat < lat_bounds[1])\n",
    "                    .where(ds.lon > lon_bounds[0])\n",
    "                    .where(ds.lon < lon_bounds[1])\n",
    "                    .sel(time=time_slice)\n",
    "                )\n",
    "\n",
    "                # hacky way of finding non-ocean (note for northeast- this does not mask\n",
    "                # out the Great Lakes- I need a land mask for that)\n",
    "                mask = (\n",
    "                    ds[\"tasmax\"]\n",
    "                    .where(ds.lat > lat_bounds[0])\n",
    "                    .where(ds.lat < lat_bounds[1])\n",
    "                    .where(ds.lon > lon_bounds[0])\n",
    "                    .where(ds.lon < lon_bounds[1])\n",
    "                    .isel(time=0)\n",
    "                    > 0\n",
    "                )\n",
    "\n",
    "                print(gcm, scenario)\n",
    "\n",
    "                precipitation.loc[gcm].loc[scenario].loc[region] = (\n",
    "                    ds_box[\"pr\"]\n",
    "                    .where(mask)\n",
    "                    .sum(dim=\"time\")\n",
    "                    .mean(dim=[\"x\", \"y\"])\n",
    "                    .values[0]\n",
    "                )\n",
    "                tasmax.loc[gcm].loc[scenario].loc[region] = (\n",
    "                    ds_box[\"tasmax\"]\n",
    "                    .where(mask)\n",
    "                    .mean(dim=\"time\")\n",
    "                    .mean(dim=[\"x\", \"y\"])\n",
    "                    .values[0]\n",
    "                )\n",
    "                tasmin.loc[gcm].loc[scenario].loc[region] = (\n",
    "                    ds_box[\"tasmax\"]\n",
    "                    .where(mask)\n",
    "                    .mean(dim=\"time\")\n",
    "                    .mean(dim=[\"x\", \"y\"])\n",
    "                    .values[0]\n",
    "                )\n",
    "\n",
    "            except:\n",
    "                print(\"uh oh! {} {} doesnt work\".format(gcm, scenario))\n",
    "        # Feels like it would be cleaner if I just took a .sel(x=slice()) approach...\n",
    "        # but that got messy with the meters units so this feels like\n",
    "        # it's longer but also more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_bounding_boxes.keys():\n",
    "    print(region)\n",
    "    lat_bounds = region_bounding_boxes[region][\"lat\"]\n",
    "    lon_bounds = region_bounding_boxes[region][\"lon\"]\n",
    "\n",
    "    for (experiment, scenario, time_slice) in scenarios:\n",
    "        for gcm in models:\n",
    "            store_url = f\"downscaling/bias-correction/{experiment}.{gcm}.{scenario}.Amon.gn\"\n",
    "            store = zarr.storage.ABSStore(\n",
    "                \"carbonplan-scratch\",\n",
    "                prefix=store_url,\n",
    "                account_name=\"carbonplan\",\n",
    "                account_key=os.environ[\"BLOB_ACCOUNT_KEY\"],\n",
    "            )\n",
    "            try:\n",
    "                ds = xr.open_zarr(store, consolidated=True)\n",
    "                print(store_url)\n",
    "                ds_box = (\n",
    "                    ds.where(ds.lat > lat_bounds[0])\n",
    "                    .where(ds.lat < lat_bounds[1])\n",
    "                    .where(ds.lon > lon_bounds[0])\n",
    "                    .where(ds.lon < lon_bounds[1])\n",
    "                    .sel(time=time_slice)\n",
    "                )\n",
    "\n",
    "                # hacky way of finding non-ocean (note for northeast- this does not mask\n",
    "                # out the Great Lakes- I need a land mask for that)\n",
    "                mask = (\n",
    "                    ds[\"tasmax\"]\n",
    "                    .where(ds.lat > lat_bounds[0])\n",
    "                    .where(ds.lat < lat_bounds[1])\n",
    "                    .where(ds.lon > lon_bounds[0])\n",
    "                    .where(ds.lon < lon_bounds[1])\n",
    "                    .isel(time=0)\n",
    "                    > 0\n",
    "                )\n",
    "\n",
    "                print(gcm, scenario)\n",
    "\n",
    "                precipitation.loc[gcm].loc[scenario].loc[region] = (\n",
    "                    ds_box[\"pr\"]\n",
    "                    .where(mask)\n",
    "                    .sum(dim=\"time\")\n",
    "                    .mean(dim=[\"x\", \"y\"])\n",
    "                    .values[0]\n",
    "                )\n",
    "                tasmax.loc[gcm].loc[scenario].loc[region] = (\n",
    "                    ds_box[\"tasmax\"]\n",
    "                    .where(mask)\n",
    "                    .mean(dim=\"time\")\n",
    "                    .mean(dim=[\"x\", \"y\"])\n",
    "                    .values[0]\n",
    "                )\n",
    "                tasmin.loc[gcm].loc[scenario].loc[region] = (\n",
    "                    ds_box[\"tasmax\"]\n",
    "                    .where(mask)\n",
    "                    .mean(dim=\"time\")\n",
    "                    .mean(dim=[\"x\", \"y\"])\n",
    "                    .values[0]\n",
    "                )\n",
    "\n",
    "            except:\n",
    "                print(\"uh oh! {} {} doesnt work\".format(gcm, scenario))\n",
    "        # Feels like it would be cleaner if I just took a .sel(x=slice()) approach...\n",
    "        # but that got messy with the meters units so this feels like\n",
    "        # it's longer but also more readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can take the future/historical parts of that array and take a delta\n",
    "(either aboslutely or relatively) to create an array with just the future\n",
    "scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_precipitation = (\n",
    "    precipitation.sel(scenario=[\"ssp245\", \"ssp370\", \"ssp585\"])\n",
    "    / precipitation.sel(scenario=\"historical\")\n",
    "    * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_tasmax = tasmax.sel(scenario=[\"ssp245\", \"ssp370\", \"ssp585\"]) - tasmax.sel(\n",
    "    scenario=\"historical\"\n",
    ")\n",
    "delta_tasmin = tasmin.sel(scenario=[\"ssp245\", \"ssp370\", \"ssp585\"]) - tasmin.sel(\n",
    "    scenario=\"historical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have temperature and precip so we'll want to make an x-y scatter plot showing\n",
    "the changes in climate for each of our different climate simulations. We'll\n",
    "focus on the downscaled simulations since that's what is actually being fed into\n",
    "the subsequent drought/insect/fire models. While repeating these analyses for\n",
    "the raw vs. downscaled datasets would also be relevant, ideally the\n",
    "downscaling/bias-correction method should preserve the precip/temp deltas and so\n",
    "the difference between raw and downscaled deltas should be negligble.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot changes of precip (%-age), temp (absolute) for different regions and different time periods\n",
    "### so it'll be 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xarray data array and populate labeled array with the historical values and the future values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of these analyses we assume that the average temperature at the\n",
    "surface is the average of maximum and minimum temperatures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(x=slice(35, 50), y=slice(-122, -110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
